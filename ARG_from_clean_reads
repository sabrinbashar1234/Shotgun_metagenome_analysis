## Clone the ARGs-OAP repository: (used beluga)
git clone https://github.com/xinehc/args_oap.git
cd args_oap
##Ensure the required dependencies are available on Beluga:

#Python 3.7 or higher 
python --version
#Diamond 2.0.15 or higher
diamond version
#BWA 0.7.17 or higher
bwa
#BLAST 2.12 or higher
blastn -version
#Samtools 1.15 or higher
samtools --version
 #Pandas

##Install ARGs-OAP using Python's setup tools:
python setup.py install --user
#Add ARGs-OAP to my PATH:
Edit your .bashrc or .bash_profile file (usually located in home directory). I can use a text editor like nano or vim.
#Add the following line to the end of the file:
export PATH="$PATH:/home/sbashar/.local/bin"
#Apply the changes to your current session by running:
source ~/.bashrc  or source ~/.bash_profile
#Verify the installation:
args_oap -h
which args_oap
args_oap --version
args_oap -h
args_oap stage_one -h
args_oap stage_two -h

##stage 1

#!/bin/bash
#SBATCH --time=12:00:00
#SBATCH --mem=64G
#SBATCH --account=def-account name
#SBATCH --output=/home/sbashar/scratch/log_ARG_OAP_stage1/log_ARG_OAP_stage1_%A_%a.log
#SBATCH --array=1-908%25

set -e
set -x

# Load modules
module load python/3.11.5
module load diamond/2.1.8
module load bwa/0.7.18
module load blast+/2.14.1
module load samtools/1.20

# Set working directory
cd /home/sbashar/scratch
mkdir -p ARG_OAP_output_stage1
cd ARG_OAP_output_stage1

# Read SRR numbers from CSV file
mapfile -t srr_folders < /home/sbashar/scratch/SRR_1000.csv

# Get the current SRR number based on the array task ID
srr=${srr_folders[$SLURM_ARRAY_TASK_ID-1]}

echo "Processing $srr - Stage One"

# Check if this sample has already been processed
if [ -d "${srr}_output" ] && [ -f "${srr}_output/extracted.fa" ]; then
    echo "Sample $srr has already been processed. Skipping."
    exit 0
fi

# Create sample-specific directory structure
sample_dir="$srr"
input_dir="$sample_dir/raw"
mkdir -p "$input_dir"

# Check if input files exist
input_file1="/home/sbashar/scratch/Host_contamination_final/$srr/${srr}_1.paired_clean.fq.gz"
input_file2="/home/sbashar/scratch/Host_contamination_final/$srr/${srr}_2.paired_clean.fq.gz"

if [ ! -f "$input_file1" ] || [ ! -f "$input_file2" ]; then
    echo "Error: Input files for $srr do not exist. Skipping this sample."
    exit 1
fi

# Create symlinks with proper naming convention
ln -sf "$input_file1" "$input_dir/${srr}_1.fq.gz"
ln -sf "$input_file2" "$input_dir/${srr}_2.fq.gz"

# Run stage_one with proper sample naming
args_oap stage_one \
    -i "$input_dir" \
    -o "${srr}_output" \
    -f fq.gz

echo "Stage One complete for $srr"


##stage 2 (the code saved as a 'stage_2_array_500.sh')

#!/bin/bash
#SBATCH --time=4:00:00
#SBATCH --mem=32G
#SBATCH --account=def-kozyrsky
#SBATCH --output=/home/sbashar/scratch/log_ARG_OAP_stage1/log_ARG_OAP_stage2_%A_%a.log
#SBATCH --array=1-500  # Process first 500 samples

set -e
set -x

# Load modules
module load python/3.11.5
module load blast+/2.14.1

# Set working directory
cd /home/sbashar/scratch/ARG_OAP_output_stage1

# Read first 500 SRR numbers from CSV file
mapfile -t srr_list < <(head -500 /home/sbashar/scratch/SRR_1000.csv)  ##for first 500 samples of the list, after 500 (lines 501-1028) the command used: mapfile -t srr_list < <(tail -n +501 /home/sbashar/scratch/SRR_1000.csv)
srr=${srr_list[$SLURM_ARRAY_TASK_ID-1]}

echo "Processing $srr - Stage Two"

# Input/output paths
input_dir="${srr}_output"
output_dir="${srr}_final_output"

# Check if already processed
if [ -d "$output_dir" ]; then
    echo "$output_dir already exists. Skipping."
    exit 0
fi

# Run stage_two
args_oap stage_two \
    -i "$input_dir" \
    -o "$output_dir"

echo "Stage Two complete for $srr"
ls -l "$output_dir"


##################################################################
#merging type and subtype of ARG (rpkm)
##need to modify the first column as in subtype file the first column has tab seperated word
##fixing the name of subtype (rpkm) of first column
 
cd /home/account_name/scratch/ARG_OAP_output_stage1 ##move to the directory where SRR*_final_output (rpkm_subtype) are

for f in *_final_output/rpkm.subtype.txt; do
    awk -F'\t' 'BEGIN{OFS=FS} {gsub(/ /, "_", $1); print}' "$f" > "${f}.tmp" && mv "${f}.tmp" "$f"
done

##merging subtype (rpkm)
[account_name@beluga4 scratch]$ cat  rpkm_subtype.sh
#!/bin/bash

# Define the output directory (adjust if needed)
ARG_OAP_DIR="/home/account_name/scratch/ARG_OAP_output_stage1"
OUTPUT_FILE="/home/account_name/scratch/merged_rpkm_subtype_1936.csv"

# Find all rpkm.subtype.txt files
FILES=($(find "$ARG_OAP_DIR" -type f -name "rpkm.subtype.txt"))

# Initialize data structures
declare -A data
declare -A subtypes
declare -A samples

# Process each file
for FILE in "${FILES[@]}"; do
    # Extract sample ID from the parent directory name
    SAMPLE_ID=$(basename "$(dirname "$FILE")")
    SAMPLE_ID=${SAMPLE_ID%_final_output}  # Remove suffix if any
    samples["$SAMPLE_ID"]=1

    # Read the file and store data
    while IFS=$'\t' read -r subtype value; do
        [[ -z "$subtype" || "$subtype" == "subtype" ]] && continue
        subtypes["$subtype"]=1
        data["$subtype,$SAMPLE_ID"]="$value"
    done < <(tr -d '\r' < "$FILE")
done

# Sort sample IDs and subtypes
SAMPLE_IDS=($(printf '%s\n' "${!samples[@]}" | sort -V))
SUBTYPE_NAMES=($(printf '%s\n' "${!subtypes[@]}" | sort))

# Write output file
{
    echo -n "subtype"
    for SAMPLE in "${SAMPLE_IDS[@]}"; do
        echo -n ",$SAMPLE"
    done
    echo ""
    for SUBTYPE in "${SUBTYPE_NAMES[@]}"; do
        echo -n "$SUBTYPE"
        for SAMPLE in "${SAMPLE_IDS[@]}"; do
            echo -n ",${data["$SUBTYPE,$SAMPLE"]:-0}"
        done
        echo ""
    done
} > "$OUTPUT_FILE"

echo "✅ Merged file created at: $OUTPUT_FILE"

##Ensure script is executable
chmod +x rpkm_subtype.sh
##Run it in bash
./rpkm_subtype.sh

##merging ARG type (rpkm)

[ACCOUNT@beluga4 scratch]$ cat merged_all_LOS_ARG.sh
#!/bin/bash

# Define the output directory (current working dir or adjust as needed)
ARG_OAP_DIR="/home/account_name/scratch/ARG_OAP_output_stage1"
OUTPUT_FILE="/home/account_name/scratch/merged_rpkm_type_1936.csv"

# Find all rpkm.type.txt files
FILES=($(find "$ARG_OAP_DIR" -type f -name "rpkm.type.txt"))

# Initialize data structures
declare -A data
declare -A types
declare -A samples

# Process each file
for FILE in "${FILES[@]}"; do
    # Extract sample ID from the parent directory name
    SAMPLE_ID=$(basename "$(dirname "$FILE")")
    SAMPLE_ID=${SAMPLE_ID%_final_output}  # Remove suffix
    samples["$SAMPLE_ID"]=1

    # Read the file and store data
    while IFS=$'\t' read -r type value; do
        [[ -z "$type" || "$type" == "type" ]] && continue
        types["$type"]=1
        data["$type,$SAMPLE_ID"]="$value"
    done < <(tr -d '\r' < "$FILE")
done

# Sort sample IDs and types
SAMPLE_IDS=($(printf '%s\n' "${!samples[@]}" | sort -V))
TYPE_NAMES=($(printf '%s\n' "${!types[@]}" | sort))

# Write output file
{
    echo -n "type"
    for SAMPLE in "${SAMPLE_IDS[@]}"; do
        echo -n ",$SAMPLE"
    done
    echo ""
    for TYPE in "${TYPE_NAMES[@]}"; do
        echo -n "$TYPE"
        for SAMPLE in "${SAMPLE_IDS[@]}"; do
            echo -n ",${data["$TYPE,$SAMPLE"]:-0}"
        done
        echo ""
    done
} > "$OUTPUT_FILE"

echo "✅ Merged file created at: $OUTPUT_FILE"

##Ensure script is executable
chmod +x merged_all_LOS_ARG.sh
##Run it in bash
./merged_all_LOS_ARG.sh

















