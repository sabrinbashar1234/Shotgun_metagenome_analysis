##Worked in Beluga
##In Alliance the tools are already installed except Sickle. I used only Trimmomatic
##Before running Trimmomatic:
    #I made sure all fastq file has accessible permission
    #I divided into 6 tasks (for 2934 samples) of array (each had 500 arrays) as Alliance has a job limit


##Final trimmomatic code for 500 arrays (here first 500 given):

#!/bin/bash
#SBATCH --account=def-account #change account name
#SBATCH --job-name=trim_first_500_mar3
#SBATCH --time=00:30:00
#SBATCH --mem=4G
#SBATCH --output=/home/account_name/scratch/trim_logs/trim_500_%a.out #change account name
#SBATCH --error=/home/account_name/scratch/trim_logs/trim_500_%a.err  #change account name
#SBATCH --array=1-500%25
#SBATCH --cpus-per-task=4

# Load necessary modules
module load trimmomatic

# Set variables
SCRATCH_DIR="/home/account_name/scratch"  #change account name
MISSING_SRS_DIR="$SCRATCH_DIR/missing_SRS_144"  # Corrected Path
#TOOLS_DIR="$SCRATCH_DIR/tools" # Not Needed
CSV_FILE="$SCRATCH_DIR/srs_first_500.csv" ##changed the .csv according to the SRS.trim.csv mentioned below

# Make sure the CSV file exists
if [ ! -f "$CSV_FILE" ]; then
  echo "Error: CSV file $CSV_FILE not found."
  exit 1
fi

# Get the SRS folder name from the CSV file based on the array index
SRS_FOLDER=$(sed "${SLURM_ARRAY_TASK_ID}q;d" "$CSV_FILE")

echo "SLURM_ARRAY_TASK_ID: $SLURM_ARRAY_TASK_ID"
echo "CSV_FILE: $CSV_FILE"
echo "SRS_FOLDER from CSV: $SRS_FOLDER"

# Check if the SRS folder exists
if [ ! -d "$MISSING_SRS_DIR/$SRS_FOLDER" ]; then
  echo "Error: SRS folder $MISSING_SRS_DIR/$SRS_FOLDER does not exist."
  exit 1
fi

# Find the SRR folder inside the SRS folder
SRR_FOLDER=$(find "$MISSING_SRS_DIR/$SRS_FOLDER" -maxdepth 1 -type d -name "SRR*")
echo "SRR_FOLDER: $SRR_FOLDER"

# Check if SRR folder exists
if [ -z "$SRR_FOLDER" ]; then
    echo "Error: No SRR folder found inside $MISSING_SRS_DIR/$SRS_FOLDER"
    exit 1
fi

# Extract the SRR ID from the path
SRR_ID=$(basename "$SRR_FOLDER")
echo "SRR_ID: $SRR_ID"

# Define input FASTQ files
INPUT_1="$SRR_FOLDER/${SRR_ID}_1.fastq.gz"
INPUT_2="$SRR_FOLDER/${SRR_ID}_2.fastq.gz"
echo "INPUT_1: $INPUT_1"
echo "INPUT_2: $INPUT_2"

# Check if input files exist
if [ ! -f "$INPUT_1" ] || [ ! -f "$INPUT_2" ]; then
    echo "Error: Input FASTQ files not found for $SRR_ID"
    echo "Looking for: $INPUT_1 and $INPUT_2"
    exit 1
fi

# Define output file names
OUTPUT_BASE="$SCRATCH_DIR/trimmomatic_output/$SRS_FOLDER/$SRR_ID"
OUTPUT_1_CLEAN="$OUTPUT_BASE.1.clean.fq.gz"
OUTPUT_1_UNPAIRED="$OUTPUT_BASE.1.unpaired.fq.gz"
OUTPUT_2_CLEAN="$OUTPUT_BASE.2.clean.fq.gz"
OUTPUT_2_UNPAIRED="$OUTPUT_BASE.2.unpaired.fq.gz"

# Create the output directory if it doesn't exist
mkdir -p "$SCRATCH_DIR/trimmomatic_output/$SRS_FOLDER"

# Run Trimmomatic
java -Xmx2g -jar $EBROOTTRIMMOMATIC/trimmomatic-0.39.jar PE \
    -threads $SLURM_CPUS_PER_TASK \
    -trimlog "$SCRATCH_DIR/trimmomatic_output/$SRS_FOLDER/$SRR_ID.trimlog" \
    "$INPUT_1" "$INPUT_2" \
    "$OUTPUT_1_CLEAN" "$OUTPUT_1_UNPAIRED" "$OUTPUT_2_CLEAN" "$OUTPUT_2_UNPAIRED" \
    ILLUMINACLIP:"$ADAPTER_FILE":2:30:10 \
    LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36

echo "Trimmomatic completed for $SRS_FOLDER / $SRR_ID"

##check all the SRS folders contain the 4 desired files mentioned in the code; the file named 'check_srs_files.sh':
#!/bin/bash

# Define the required file patterns
REQUIRED_FILES=(
  "*.1.clean.fq.gz"
  "*.1.unpaired.fq.gz"
  "*.2.clean.fq.gz"
  "*.2.unpaired.fq.gz"
)

# Loop through each SRS* folder
for SRS_FOLDER in SRS*; do
  # Check if it's a directory
  if [ ! -d "$SRS_FOLDER" ]; then
    continue  # Skip if it's not a directory
  fi

  MISSING_FILES=()

  # Loop through each required file pattern
  for FILE_PATTERN in "${REQUIRED_FILES[@]}"; do
    # Find files matching the current pattern in the current SRS folder
    FILES=$(find "$SRS_FOLDER" -maxdepth 1 -type f -name "$FILE_PATTERN")

    # If no files are found, add the pattern to the MISSING_FILES array
    if [ -z "$FILES" ]; then
      MISSING_FILES+=("$FILE_PATTERN")
    fi
  done

  # If there are any missing files, report them
  if [ ${#MISSING_FILES[@]} -gt 0 ]; then
    echo "SRS folder '$SRS_FOLDER' is missing the following files:"
    for MISSING_FILE in "${MISSING_FILES[@]}"; do
      echo "  - $MISSING_FILE"
    done
  fi
done

##using bbduk for Phix Adapter contamination
##generated csv files for SRS list from where the code recognized SRS folder and created output based on SRR number

#!/bin/bash
#SBATCH --account=def-account name
#SBATCH --job-name=bbmap_srs_array_418
#SBATCH --time=2:00:00       # Adjust time as needed
#SBATCH --mem=4G           # Adjust memory as needed
#SBATCH --cpus-per-task=4    # Adjust CPUs as needed
#SBATCH --array=1-418%25      # Array job, process 418, limit concurrency to 25
#SBATCH --output=/home/account_name/scratch/bbmap_srs_array_418_%a.out
#SBATCH --error=/home/account_name/scratch/bbmap_srs_array_418_%a.err

# --- Load Modules ---
module load bbmap

# --- Variables ---
SCRATCH_DIR="/home/account_name/scratch"              ##change account name
ANALYSIS_FOLDER="$SCRATCH_DIR"
TRIMMOMATIC_OUTPUT="$SCRATCH_DIR/trimmomatic_output"  # Corrected path
BBMAP_OUTPUT="$SCRATCH_DIR/bbmap_output_501_1000"
TOOLS_FOLDER="$SCRATCH_DIR/tools"

# --- Input CSV file (now a local file) ---
SRS_LIST_FILE="$SCRATCH_DIR/nw_SRS_417.csv"      ##change csv file for the list

# --- Create main output directory ---
mkdir -p "$BBMAP_OUTPUT"

# --- Function to process paired data ---
process_paired() {
  local srs_dir="$1"
 # Get the SRS folder name
  srs_folder=$(basename "$srs_dir")

  # Find paired clean files
  cleanlist=$(find "$srs_dir" -maxdepth 1 -name "*1.clean.fq.gz")

  echo "Running bbduk for paired data in $srs_dir"

  for s in $cleanlist; do
    # Extract SRR ID from the input filename
    srr_id=$(echo "$s" | sed -E 's/.*\/(SRR[^/]+)\.1\.clean\.fq\.gz/\1/')

    # Create SRR-specific output directory
    local SRR_BBMAP_OUTPUT="$BBMAP_OUTPUT/${srr_id}"
    mkdir -p "$SRR_BBMAP_OUTPUT"

    s=$(echo "$s" | tr -d '\n')
    in2=$(echo "$s" | sed -e "s/1.clean.fq.gz/2.clean.fq.gz/")
    echo "Processing paired files: $s and $in2"

    bbduk.sh \
      threads=$SLURM_CPUS_PER_TASK \
      in="$s" \
      in2="$in2" \
      k=31 \
      ref="$EBROOTBBMAP/resources/sequencing_artifacts.fa.gz,$EBROOTBBMAP/resources/phix_adapters.fa.gz" \
      out1="$SRR_BBMAP_OUTPUT/${srr_id}_1.paired.bbdukclean.fq.gz" \
      out2="$SRR_BBMAP_OUTPUT/${srr_id}_2.paired.bbdukclean.fq.gz" \
   minlength=60
  done
}

# --- Function to process unpaired data ---
process_unpaired() {
  local srs_dir="$1"

  # Get the SRS folder name
  srs_folder=$(basename "$srs_dir")

  # Find unpaired files
  unpairedlist=$(find "$srs_dir" -maxdepth 1 -name "*unpaired.fq.gz")

  echo "Running bbduk for unpaired data in $srs_dir"

  for s in $unpairedlist; do
    # Extract SRR ID from the full path (using a simpler regex)
    srr_id=$(basename "$s" | sed 's/\..*//')

    # Create SRR-specific output directory
    local SRR_BBMAP_OUTPUT="$BBMAP_OUTPUT/${srr_id}"
    mkdir -p "$SRR_BBMAP_OUTPUT"

    s=$(echo "$s" | tr -d '\n')
    echo "Processing unpaired file: $s"
 bbduk.sh \
      threads=$SLURM_CPUS_PER_TASK \
      in="$s" \
      k=31 \
      ref="$EBROOTBBMAP/resources/sequencing_artifacts.fa.gz,$EBROOTBBMAP/resources/phix_adapters.fa.gz" \
      out="$SRR_BBMAP_OUTPUT/$(basename "$s").bbdukclean.fq.gz" \
      minlength=60
  done
}

# --- Main processing loop ---
# Read the specified line from the file
srs_dir=$(sed -n "${SLURM_ARRAY_TASK_ID}p" "$SRS_LIST_FILE")

# --- Process only if a line was read ---
if [ -n "$srs_dir" ]; then
    # --- Check if the SRS directory exists ---
    if [ -d "$TRIMMOMATIC_OUTPUT/$srs_dir" ]; then
      srs_dir="$TRIMMOMATIC_OUTPUT/$srs_dir"  # Prepend the full path

      echo "Processing SRS directory: $srs_dir (from list, array task: ${SLURM_ARRAY_TASK_ID})"
      process_paired "$srs_dir"
      process_unpaired "$srs_dir"
    else
      echo "Warning: SRS directory '$srs_dir' not found in TRIMMOMATIC_OUTPUT. Skipping."
  fi
else
  echo "SLURM_ARRAY_TASK_ID out of range or empty line in file. Skipping."
fi

echo "DONE"


##Host contamination checking by BBMAP
#reference genome (Human) download
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz
gunzip GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz
#index file creation (as beluga was unable to indexing from ref file, indexing was done again)
#!/bin/bash
#SBATCH --account=def-accountname
#SBATCH --job-name=index_genome
#SBATCH --time=12:00:00
#SBATCH --mem=64G
#SBATCH --cpus-per-task=8
#SBATCH --output=index_genome.out
#SBATCH --error=index_genome.err

# Load the required environment
module purge
module load StdEnv/2023
module load bbmap/39.06

# Unset JAVA_TOOL_OPTIONS to avoid memory issues
unset JAVA_TOOL_OPTIONS

# Run BBMap indexing with increased memory allocation
bbmap.sh -Xmx58G ref=/home/account_name/scratch/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna path=/home/account_name/scratch/ref/genome/1


##BBMAP script for host contamination checking

#!/bin/bash
#SBATCH --account=def-accountname
#SBATCH --job-name=bbmap_host_test_1001_1500
#SBATCH --time=1:00:00
#SBATCH --mem=32G
#SBATCH --cpus-per-task=8
#SBATCH --array=1-500
#SBATCH --output=/home/account_name/scratch/log_host_contamination/bbmap_host_test_1001_1500_%A_%a.out
#SBATCH --error=/home/account_name/scratch/log_host_contamination/bbmap_host_test_1001_1500_%A_%a.err

# --- Load Modules ---
module purge
module load StdEnv/2023 bbmap/39.06
module load java

# --- Unset JAVA_TOOL_OPTIONS ---
unset JAVA_TOOL_OPTIONS

# --- Variables ---
SCRATCH_DIR="/home/account_name/scratch"
BBMAP_OUTPUT="$SCRATCH_DIR/bbmap_output_501_1000"
INDEXED_REF="/home/account_name/scratch/ref/genome/1"  # Path to indexed genome
OUTPUT_DIR="$SCRATCH_DIR/Host_contamination"

# --- Create main output directory ---
mkdir -p "$OUTPUT_DIR"

# --- Get list of SRR directories (1001st to 1500th) ---
mapfile -t SRR_DIRS < <(ls -d "$BBMAP_OUTPUT"/SRR* | sed -n '1001,1500p') ##the SRR folder selection (1001-1500)

# --- Get the SRR directory for this task ---
srr_dir="${SRR_DIRS[SLURM_ARRAY_TASK_ID-1]}"
srr_name=$(basename "$srr_dir")
srr_output_dir="$OUTPUT_DIR/$srr_name"

# Create a separate output directory for each SRR ID
mkdir -p "$srr_output_dir"

echo "Processing: $srr_dir"
echo "Output directory for $srr_name: $srr_output_dir"

# --- Functions ---
bbmap_QC2() {
    echo "Running bbmap 2 for $srr_name"
    
    # Define the expected input file names
    bbduklist=(
        "$srr_dir/${srr_name}_1.paired.bbdukclean.fq.gz"
        "$srr_dir/${srr_name}_2.paired.bbdukclean.fq.gz"
        "$srr_dir/${srr_name}.1.unpaired.fq.gz.bbdukclean.fq.gz"
        "$srr_dir/${srr_name}.2.unpaired.fq.gz.bbdukclean.fq.gz"
    )

    echo "Running bbwrap for $srr_name"
    for s in "${bbduklist[@]}"; do
        if [ -f "$s" ]; then
            echo "Processing file: $s"
            
            # Determine read type and pair
            if [[ "$s" == *"_1.paired."* ]]; then
                in2_file=$(echo "$s" | sed 's/_1.paired./_2.paired./g')
                read_type="paired"
                output_prefix="$srr_output_dir/${srr_name}"
            elif [[ "$s" == *"_2.paired."* ]]; then
                # Skip processing for _2.paired files here, as they'll be handled with _1.paired
                continue
            else
                in2_file="NULL"
                read_type="unpaired"
                output_prefix="$srr_output_dir/${srr_name}_$(basename "${s%.bbdukclean.fq.gz}")"
            fi
            
            echo "bbwrap input: $s | Type: $read_type"
            echo "Output prefix: $output_prefix"

            # Run bbwrap with indexed reference
            if [ "$read_type" == "paired" ]; then
                bbwrap.sh -Xmx24G \
                    threads=$SLURM_CPUS_PER_TASK \
                    minid=0.95 \
                    maxindel=3 \
                    bwr=0.16 \
                    bw=12 \
                    quickmatch \
                    fast \
                    minhits=2 \
                    path="$INDEXED_REF" \
                    in="$s" \
                    in2="$in2_file" \
                    outm1="${output_prefix}_1.paired_human.fq.gz" \
                    outm2="${output_prefix}_2.paired_human.fq.gz" \
                    outu1="${output_prefix}_1.paired_clean.fq.gz" \
                    outu2="${output_prefix}_2.paired_clean.fq.gz"
            else
                bbwrap.sh -Xmx24G \
                    threads=$SLURM_CPUS_PER_TASK \
                    minid=0.95 \
                    maxindel=3 \
                    bwr=0.16 \
                    bw=12 \
                    quickmatch \
                    fast \
                    minhits=2 \
                    path="$INDEXED_REF" \
                    in="$s" \
                    outm="${output_prefix}_human.fq.gz" \
                    outu="${output_prefix}_clean.fq.gz"
            fi

        else
            echo "Warning: Input file not found: $s"
        fi
    done

    # Run bbmerge on paired clean reads (if they exist)
    echo "Running bbmerge for $srr_name"
    paired_clean_1="$srr_output_dir/${srr_name}_1.paired_clean.fq.gz"
    paired_clean_2="$srr_output_dir/${srr_name}_2.paired_clean.fq.gz"

    if [ -f "$paired_clean_1" ] && [ -f "$paired_clean_2" ]; then
        echo "Merging paired reads: $paired_clean_1 and $paired_clean_2"

        bbmerge.sh -Xmx8G \
            threads=4 \
            in1="$paired_clean_1" \
            in2="$paired_clean_2" \
            out="$srr_output_dir/${srr_name}_merged.final.clean.fq.gz" \
            outu1="$srr_output_dir/${srr_name}_1.unmerged.final.clean.fq.gz" \
            outu2="$srr_output_dir/${srr_name}_2.unmerged.final.clean.fq.gz"

        echo "bbmerge completed successfully for $srr_name"
    else
        echo "Warning: Paired clean reads not found for merging."
        echo "Missing files:"
        [ ! -f "$paired_clean_1" ] && echo "- $paired_clean_1"
        [ ! -f "$paired_clean_2" ] && echo "- $paired_clean_2"
    fi
}

# --- Main Process ---
bbmap_QC2

# --- Final Verification ---
echo "Output files created in $srr_output_dir:"
ls -lh "$srr_output_dir"

echo "Process completed successfully for $srr_name."



















##Install necessary packages (the sbatch code was saved as 'install_tools.sh' and all the tools saved in 'tools' folder in scratch:

#!/bin/bash

#SBATCH --account=def-account name
#SBATCH --time=10:00:00
#SBATCH --job-name=install_qc_tools
#SBATCH --output=output.txt
#SBATCH --error=error.txt

# Set the tools folder in your scratch directory
TOOLS_FOLDER="$SCRATCH/tools"
FASTQC_VERSION="v0.11.9"

# Create the tools folder if it doesn't exist
mkdir -p $TOOLS_FOLDER

# Function to install FastQC
install_fastqc() {
    echo "Installing FastQC"
    cd $TOOLS_FOLDER
    wget https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_${FASTQC_VERSION}.zip
    unzip fastqc_${FASTQC_VERSION}.zip
    chmod 755 FastQC/fastqc
    rm fastqc_${FASTQC_VERSION}.zip
}

# Function to install Trimmomatic
install_trimmomatic() {
    echo "Installing Trimmomatic"
    cd $TOOLS_FOLDER
    wget http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/Trimmomatic-0.39.zip
    unzip Trimmomatic-0.39.zip
    rm Trimmomatic-0.39.zip
}

# Function to install Sickle
install_sickle() {
    echo "Installing Sickle"
    cd $TOOLS_FOLDER
    wget https://github.com/najoshi/sickle/archive/v1.33.tar.gz
    tar -xzvf v1.33.tar.gz
    cd sickle-1.33/
    make
    cd ..
    rm v1.33.tar.gz
}
# Function to install BBMap
install_bbmap() {
    echo "Installing BBMap"
    cd $TOOLS_FOLDER
    wget https://sourceforge.net/projects/bbmap/files/BBMap_38.44.tar.gz
    tar -xzvf BBMap_38.44.tar.gz
    rm BBMap_38.44.tar.gz
}

# Function to install Prinseq
install_prinseq() {
    echo "Installing Prinseq"
    cd $TOOLS_FOLDER
    wget https://sourceforge.net/projects/prinseq/files/standalone/prinseq-lite-0.20.4.tar.gz
    tar -xzvf prinseq-lite-0.20.4.tar.gz
    rm prinseq-lite-0.20.4.tar.gz
}

# Install all tools
install_fastqc
install_trimmomatic
install_sickle
install_bbmap
install_prinseq

echo "All tools have been installed in $TOOLS_FOLDER"


## Trimmomatric test
# first I created first 500 SRS number using this code as cloud did not support 2934 arrays:

head -n 500 /home/sbashar/scratch/srs_all_144_folders.csv > /home/sbashar/scratch/srs_first_500.csv
##for next 500*5 files the files were created in this way:
 tail -n +1001 /home/sbashar/scratch/srs_all_144_folders.csv | head -n 500 > /home/sbashar/scratch/srs_1001-1500.csv
tail -n +1501 /home/sbashar/scratch/srs_all_144_folders.csv | head -n 500 > /home/sbashar/scratch/srs_1501-2000.csv
tail -n +2001 /home/sbashar/scratch/srs_all_144_folders.csv | head -n 500 > /home/sbashar/scratch/srs_2001-2500.csv
tail -n +2501 /home/sbashar/scratch/srs_all_144_folders.csv | head -n 500 > /home/sbashar/scratch/srs_2501-2934.csv

##how I created fastq permission. I divided SRS number into 3 part (1000 SRS for each job). This code is for first 1000:
#!/bin/bash
#SBATCH --account=def-kozyrsky
#SBATCH --job-name=fix_permissions_1_1000
#SBATCH --time=2:00:00       # Adjust time as needed
#SBATCH --mem=4G              # Adjust memory as needed
#SBATCH --array=1-1000        # Array job for first 1000 SRS folders
#SBATCH --output=fix_permissions_1_1000_%a.out
#SBATCH --error=fix_permissions_1_1000_%a.err
#SBATCH --cpus-per-task=4    # Request 4 CPUs per task

SCRATCH_DIR="/home/sbashar/scratch"
MISSING_SRS_DIR="/home/sbashar/scratch/missing_SRS_144" # or wherever your SRS folders are
# Calculate the SRS folder index based on the array task ID
SRS_INDEX=$SLURM_ARRAY_TASK_ID

# Create a list of SRS folders
SRS_FOLDERS=$(find "$MISSING_SRS_DIR" -maxdepth 1 -type d -name "SRS*" | sort)

# Get the specific SRS folder for this task
SRS_FOLDER=$(echo "$SRS_FOLDERS" | sed -n "${SRS_INDEX}p")

if [ -z "$SRS_FOLDER" ]; then
  echo "Error: SRS folder not found for index $SRS_INDEX"
  exit 1
fi

echo "Processing SRS folder: $SRS_FOLDER"

# Find SRR folder inside the SRS folder
SRR_FOLDER=$(find "$SRS_FOLDER" -maxdepth 1 -type d -name "SRR*")

if [ -z "$SRR_FOLDER" ]; then
  echo "  No SRR folder found in $SRS_FOLDER"
  exit 0  # Exit gracefully, not an error
fi

# Find FASTQ files inside the SRR folder
FASTQ_FILES=$(find "$SRR_FOLDER" -maxdepth 1 -type f -name "*fastq.gz")

if [ -z "$FASTQ_FILES" ]; then
  echo "  No FASTQ files found in $SRR_FOLDER"
  exit 0  # Exit gracefully, not an error
fi

# Check and correct permissions for each FASTQ file
for FASTQ_FILE in $FASTQ_FILES; do
  # Get current permissions
 PERMISSIONS=$(stat -c "%A" "$FASTQ_FILE")
  echo "   File: $FASTQ_FILE, Current Permissions: $PERMISSIONS"

  # Check if permissions are not rw-r--r--
  if [ "$PERMISSIONS" != "-rw-r--r--" ]; then
    echo "    Correcting permissions for $FASTQ_FILE"
    chmod a+r "$FASTQ_FILE"  # Add read permission for all
  fi
done
##For the second 1000 SRS, I calculate at the beginning:

#!/bin/bash
#SBATCH --account=def-kozyrsky
#SBATCH --job-name=fix_permissions_1001_2000
#SBATCH --time=2:00:00       # Adjust time as needed
#SBATCH --mem=4G              # Adjust memory as needed
#SBATCH --array=1-1000        # Array job for SRS folders 1001-2000
#SBATCH --output=fix_permissions_1001_2000_%a.out
#SBATCH --error=fix_permissions_1001_2000_%a.err
#SBATCH --cpus-per-task=4    # Request 4 CPUs per task

SCRATCH_DIR="/home/sbashar/scratch"
MISSING_SRS_DIR="/home/sbashar/scratch/missing_SRS_144" # or wherever your SRS folders are
# Calculate the SRS folder index based on the array task ID ##this part added
SRS_INDEX=$((SLURM_ARRAY_TASK_ID + 1000))

# Create a list of SRS folders
SRS_FOLDERS=$(find "$MISSING_SRS_DIR" -maxdepth 1 -type d -name "SRS*" | sort)

# Get the specific SRS folder for this task
SRS_FOLDER=$(echo "$SRS_FOLDERS" | sed -n "${SRS_INDEX}p")
.....and rest is same as above

##For next 934 SRS, the code is below:
#!/bin/bash
#SBATCH --account=def-kozyrsky
#SBATCH --job-name=fix_permissions_2001_2934
#SBATCH --time=2:00:00       # Adjust time as needed
#SBATCH --mem=4G              # Adjust memory as needed
#SBATCH --array=1-934         # Array job for SRS folders 2001-2934
#SBATCH --output=fix_permissions_2001_2934_%a.out
#SBATCH --error=fix_permissions_2001_2934_%a.err
#SBATCH --cpus-per-task=4    # Request 4 CPUs per task

SCRATCH_DIR="/home/sbashar/scratch"
MISSING_SRS_DIR="/home/sbashar/scratch/missing_SRS_144" # or wherever your SRS folders are

# Calculate the SRS folder index based on the array task ID ##here the changes added
SRS_INDEX=$((SLURM_ARRAY_TASK_ID + 2000))

# Create a list of SRS folders
SRS_FOLDERS=$(find "$MISSING_SRS_DIR" -maxdepth 1 -type d -name "SRS*" | sort)

...... the rest is same as above


